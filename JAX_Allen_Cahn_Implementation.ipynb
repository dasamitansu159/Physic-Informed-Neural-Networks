{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Umv2WrgAZAWA"
      },
      "outputs": [],
      "source": [
        "import numpy as onp\n",
        "import jax.numpy as np\n",
        "from jax import random, grad, vmap, jit\n",
        "from jax.example_libraries import optimizers\n",
        "from jax.flatten_util import ravel_pytree\n",
        "from jax import lax\n",
        "\n",
        "import itertools\n",
        "from functools import partial\n",
        "from torch.utils import data\n",
        "from tqdm import trange\n",
        "\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34K0oa_ZZhTq"
      },
      "outputs": [],
      "source": [
        "def MLP(layers, L=1.0, M=1, activation=np.tanh):\n",
        "\n",
        "  def input_encoding(t, x):\n",
        "\n",
        "    w = 2.0 * np.pi / L\n",
        "    k = np.arange(1, M + 1)\n",
        "    out = np.hstack([t, 1, np.cos(k * w * x), np.sin(k * w * x)])\n",
        "\n",
        "    return out\n",
        "\n",
        "  def init(rng_key):\n",
        "    def init_layer(key, d_in, d_out):\n",
        "      k1, k2 = random.split(key)\n",
        "      glorot_stddev = 1.0 / np.sqrt((d_in + d_out)/ 2.)\n",
        "      w = glorot_stddev * random.normal(k1, (d_in, d_out))\n",
        "      b = np.zeros(d_out)\n",
        "      return w, b\n",
        "\n",
        "    key, *keys = random.split(rng_key, len(layers))\n",
        "    params = list(map(init_layer, keys, layers[: -1], layers[1: ]))\n",
        "    return params\n",
        "\n",
        "  def apply(params, inputs):\n",
        "    t = inputs[0]\n",
        "    x = inputs[1]\n",
        "    H = input_encoding(t, x)\n",
        "    for w, b in params[: -1]:\n",
        "      outputs = np.dot(H, w) + b\n",
        "      H = activation(outputs)\n",
        "    W, b = params[-1]\n",
        "    outputs = np.dot(H, w) + b\n",
        "    return outputs\n",
        "\n",
        "  return init, apply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dM2M1gKId4rI"
      },
      "outputs": [],
      "source": [
        "class PINN:\n",
        "  def __init__(self, key, layers, M, state0, t0, t1, n_t, n_x, tol):\n",
        "\n",
        "    # collocation points\n",
        "    self.t0 = t0\n",
        "    self.t1 = t1\n",
        "    self.t_r = np.linspace(self.t0, self.t1, n_t)\n",
        "    self.x_r = np.linspace(-1, 1, n_x)\n",
        "\n",
        "    # For computing the temporal weights\n",
        "    self.M = np.triu(np.ones((n_t, n_t)), k = 1).T\n",
        "    self.tol = tol\n",
        "\n",
        "    #IC\n",
        "    t_ic = np.zeros((x_star.shape[0], 1))\n",
        "    x_ic = x_star.reshape(-1, 1)\n",
        "    self.X_ic = np.hstack([t_ic, x_ic])\n",
        "    self.Y_ic = state0\n",
        "\n",
        "    # Initialize the network\n",
        "    self.init, self.apply = MLP(layers, L = 2.0, M = M, activation = np.tanh)\n",
        "    params = self.init(rng_key = key)\n",
        "    _, self.unravel = ravel_pytree(params)\n",
        "\n",
        "    # Use optimizers to set optimizer initialization and update functions\n",
        "    lr = optimizers.exponential_decay(1e-3, decay_steps = 5000, decay_rate = 0.9)\n",
        "    self.opt_init, \\\n",
        "    self.opt_update, \\\n",
        "    self.get_params = optimizers.adam(lr)\n",
        "    self.opt_state = self.opt_init(params)\n",
        "\n",
        "    # Evaluate the network and the residual over the grid\n",
        "    self.u_pred_fn = vmap(vmap(self.neural_net, (None, 0, None)), (None, None, 0))\n",
        "    self.r_pred_fn = vmap(vmap(self.residual_net, (None, None, 0)), (None, 0, None))\n",
        "\n",
        "    # Logger\n",
        "    self.itercount = itertools.count()\n",
        "\n",
        "    self.loss_log = []\n",
        "    self.loss_ics_log = []\n",
        "    self.loss_res_log = []\n",
        "    self.w_log = []\n",
        "    self.L_t_log = []\n",
        "\n",
        "  def neural_net(self, params, t, x):\n",
        "      z = np.stack([t, x])\n",
        "      outputs = self.apply(params, z)\n",
        "      return outputs[0]\n",
        "\n",
        "  def residual_net(self, params, t, x):\n",
        "      u = self.neural_net(params, t, x)\n",
        "      u_t = grad(self.neural_net, argnums=1)(params, t, x)\n",
        "      u_x = grad(self.neural_net, argnums=2)(params, t, x)\n",
        "      u_xx = grad(grad(self.neural_net, argnums=2), argnums=2)(params, t, x)\n",
        "      return u_t + 5 * u**3 - 5 * u - nu * u_xx\n",
        "\n",
        "  @partial(jit, static_argnums=(0,))\n",
        "  def residuals_and_weights(self, params, tol):\n",
        "      r_pred = self.r_pred_fn(params, self.t_r, self.x_r)\n",
        "      L_t = np.mean(r_pred ** 2, axis =1)\n",
        "      w = lax.stop_gradient(np.exp(-tol * (self.M @ L_t)))\n",
        "      return L_t, w\n",
        "\n",
        "  @partial(jit, static_argnums=(0,))\n",
        "  def loss_ics(self, params):\n",
        "      u_pred = vmap(self.neural_net, (None, 0, 0))(params, self.X_ic[:,0], self.X_ic[:, 1])\n",
        "      loss_ics = np.mean((self.Y_ic.flatten() - u_pred.flatten()) ** 2)\n",
        "      return loss_ics\n",
        "\n",
        "  @partial(jit, static_argnums=(0,))\n",
        "  def loss_res(self, params):\n",
        "      r_pred = self.r_pred_fn(params, self.t_r, self.x_r)\n",
        "      loss_r = np.mean(r_pred ** 2)\n",
        "      return loss_r\n",
        "\n",
        "  @partial(jit, static_argnums=(0,))\n",
        "  def loss(self, params):\n",
        "      L0 =100 * self.loss_ics(params)\n",
        "      L_t, w = self.residuals_and_weights(params, self.tol)\n",
        "\n",
        "      loss = np.mean(w * L_t) + L0\n",
        "      return loss\n",
        "\n",
        "  @partial(jit, static_argnums=(0,))\n",
        "  def step(self, i, opt_state):\n",
        "      params = self.get_params(opt_state)\n",
        "      g = grad(self.loss)(params)\n",
        "\n",
        "      return self.opt_update(i, g, opt_state)\n",
        "\n",
        "  def train(self, nIter = 10000):\n",
        "      pbar=trange(nIter)\n",
        "      for it in pbar:\n",
        "        self.current_count = next(self.itercount)\n",
        "        self.opt_state = self.step(self.current_count, self.opt_state)\n",
        "\n",
        "        if it % 1000 == 0:\n",
        "          params = self.get_params(self.opt_state)\n",
        "\n",
        "          loss_value = self.loss(params)\n",
        "          loss_ics_value = self.loss_ics(params)\n",
        "          loss_res_value = self.loss_res(params)\n",
        "          L_t_value, w_value = self.residuals_and_weights(params, self.tol)\n",
        "\n",
        "          pbar.set_postfix({\"Loss\": loss_value,\n",
        "                            \"loss_ics\": loss_ics_value,\n",
        "                            \"loss_res\": loss_res_value\n",
        "                            })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIENVyy4SWiV"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "data = scipy.io.loadmat('AC.mat')\n",
        "usol = data['uu']\n",
        "\n",
        "# Grid\n",
        "t_star = data['tt'][0]\n",
        "x_star = data['x'][0]\n",
        "TT, XX = np.meshgrid(t_star, x_star)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13cING8ceRYj"
      },
      "outputs": [],
      "source": [
        "key = random.PRNGKey(1234)\n",
        "\n",
        "M = 10\n",
        "d0 = M * 2 + 2\n",
        "layers = [d0, 128, 128, 128, 128, 1]\n",
        "\n",
        "nu = 0.0001\n",
        "t0 = 0.0\n",
        "t1 = 1.0\n",
        "n_t = 100\n",
        "n_x = 256\n",
        "tol = 100\n",
        "\n",
        "state0 = usol[:, 0:1]\n",
        "\n",
        "model = PINN(key, layers, M, state0, t0, t1, n_t, n_x, tol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfONktPeSg-6",
        "outputId": "74633664-c437-4f45-da9c-4d9e9ba56383"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|‚ñè         | 2882/200000 [01:30<1:38:11, 33.46it/s, Loss=0.00029043306, loss_ics=1.4189297e-06, loss_res=1.5562316]"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "model.train(nIter=200000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qjYE_35JO0_C"
      },
      "outputs": [],
      "source": [
        "# Get trained network parameters\n",
        "params = model.get_params(model.opt_state)\n",
        "u_pred = model.u_pred_fn(params, t_star, x_star)\n",
        "error = np.mean(u_pred - usol)\n",
        "print('Absolute error: {:.6e}'.format(abs(error)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IOyU7W-9PGUf"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(18, 5))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.pcolor(TT, XX, usol, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('x')\n",
        "plt.title(r'Exact u(t,x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.pcolor(TT, XX, u_pred, cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('x')\n",
        "plt.title(r'Predicted u(t,x)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.pcolor(TT, XX, np.abs(usol - u_pred), cmap='jet')\n",
        "plt.colorbar()\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('x')\n",
        "plt.title('Absolute error')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VaeDBHkKPZGU"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(13, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(x_star, usol[:,0], color='blue')\n",
        "plt.plot(x_star, u_pred[:,0], '--', color='red')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('u(t,x)')\n",
        "plt.title('t = 0')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(x_star, usol[:,25], color='blue')\n",
        "plt.plot(x_star, u_pred[:,25], '--', color='red')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('u(t,x)')\n",
        "plt.title('t = 0.5')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(x_star, usol[:,-1], color='blue')\n",
        "plt.plot(x_star, u_pred[:,-1], '--', color='red')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('u(t,x)')\n",
        "plt.title('t = 1.0')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IE65lVhZQNmP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}